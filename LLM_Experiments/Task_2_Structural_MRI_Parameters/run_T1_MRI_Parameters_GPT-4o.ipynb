{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code: Extract MRI Parameters Via LLM (Task 2)\n",
    "\n",
    "This is the code to run the MRI Parameters prompt and papers through GPT-4o. Mostly derived from previous experiments. Each paper is combined with our fixed prompt and submitted to the LLM, and each labeling is returned as an individual JSON file.\n",
    "\n",
    "This is **step 1** for obtaining and analyzing the LLM produced annotations:\n",
    "\n",
    "1. The notebook `run_T1_MRI_Parameters_GPT-4o.ipynb` (this notebook) accesses the OpenAI API and saves the JSON responses from the LLM.\n",
    "2. `convert_MRI_JSON_parameters_to_CSV.ipynb` converts the JSON files from the LLM to a single CSV.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Imports, Kill-Switch, ENV Stuff, Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_run = False    # When True, the LLM will be used (this is for testing without hitting the API)\n",
    "\n",
    "if LLM_run:\n",
    "    print(\"LLM set to Run.\")\n",
    "else:\n",
    "    print(\"LLM not to be called.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `dotenv` but this code should also find API keys in the environment even if other methods are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenvfile = find_dotenv()\n",
    "load_dotenv(dotenvfile)      # Apparently no issues if null\n",
    "\n",
    "if dotenvfile == '':\n",
    "    print(\"No dotenv file. If OpenAI key set in environment this should still run.\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "ROOT_DIR       = os.getenv('ROOT_DIR')\n",
    "print(\"ROOT_DIR set to: \" + ROOT_DIR)\n",
    "\n",
    "if OPENAI_API_KEY == '' or OPENAI_API_KEY is None:\n",
    "    print(\"No OpenAI API key found in environment or dotenv file. See https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key.\")\n",
    "else:\n",
    "    print(\"Using OpenAI API key from environment or dotenv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check directory\n",
    "\n",
    "cwd = os.getcwd()  \n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-2024-08-06\"  # NB: 2024-08-06 is the cheapest and most recent model\n",
    "\n",
    "print(\"Using this model: \" + model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MRI_parameter_prompt.txt\") as f:\n",
    "    prompt_start = f.read()\n",
    "\n",
    "with open(\"./prototype.json\") as f:\n",
    "    prototype_JSON = f.read()\n",
    "\n",
    "base_prompt = prompt_start + prototype_JSON + \"\\n###\\n\\n\"\n",
    "\n",
    "print(base_prompt + \"Paper Text Goes Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_text = \"\"\"\n",
    "You are a helpful assistant who is expert in MRI (magnetic resonance imaging). You understand\n",
    "the parameters associated with structural MRI scans. You are careful, thorough, and brief in\n",
    "your responses. You carefully read the text presented and correctly extract from it the\n",
    "information you need to respond to the user. You format your responses exclusively as JSON using\n",
    "the guide provided in the prompt.\n",
    "\"\"\"\n",
    "\n",
    "# As above for readability, the next lines reduce the whitespace for the LLM\n",
    "\n",
    "system_prompt_text = system_prompt_text.replace(\"\\n\", \" \")\n",
    "system_prompt_text = system_prompt_text.strip()\n",
    "\n",
    "print(system_prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message List\n",
    "\n",
    "Messages to the API must be formatted as a message list. The next function combines the system prompt and the (eventual) user prompt, which itself is the combination of the text of the paper added to the end of the `base_prompt`. This function **starts** a message list, but does not update it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_message_list(user_prompt, system_prompt = system_prompt_text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "# Test\n",
    "\n",
    "start_message_list(\"This is the user message placeholder.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Ground Truth data to get the PMIDs of the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv(\"ground_truth_structural_mri_parameters_final.csv\")\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_df.shape) # Should be 44 rows based on current CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list = gt_df['pmcid'].tolist()\n",
    "paper_list = [x + \"_partial.txt\" for x in paper_list]\n",
    "print(len(paper_list))\n",
    "print(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with directories\n",
    "\n",
    "input_articles_folder = ROOT_DIR + \"/Library/Articles_Title_Thru_Methods/\"\n",
    "print(input_articles_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Runner Code\n",
    "Here is the code that actually runs everything throgh the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for API calls\n",
    "max_reply_tokens = 5000\n",
    "temp = 0\n",
    "run_date = str(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")) # Start time of run\n",
    "print(\"Using LLM model: \" + model)\n",
    "\n",
    "# Results Folders\n",
    "raw_results_dir  = ROOT_DIR + \"/LLM_Experiments/Structural_MRI_Parameters/Results/Raw_Results/OpenAI/GPT-4o/\"\n",
    "JSON_results_dir = ROOT_DIR + \"/LLM_Experiments/Structural_MRI_Parameters/Results/Inner_JSON/OpenAI/GPT-4o/\"\n",
    "\n",
    "for paper in paper_list:\n",
    "    # Setup\n",
    "    fn = input_articles_folder + paper\n",
    "    with open(fn, \"r\") as f:\n",
    "        text = f.read()\n",
    "    submit_prompt = base_prompt + text\n",
    "    ml = start_message_list(submit_prompt)\n",
    "    print(\"Starting: \", paper)\n",
    "    # LLM Call\n",
    "    if LLM_run:\n",
    "        client = OpenAI()\n",
    "        completion = client.chat.completions.create(\n",
    "            model = model,\n",
    "            response_format = { \"type\": \"json_object\" },\n",
    "            max_tokens = max_reply_tokens,\n",
    "            temperature = temp,\n",
    "            messages = ml\n",
    "        )\n",
    "    else:\n",
    "        print(\"LLM deactivated.\")  # Crash out of loop if LLM deactivated\n",
    "        break\n",
    "    # Save Results\n",
    "    response   = completion.choices[0].message.content # JSON response from LLM\n",
    "    # Filename stuff:\n",
    "    paperID = paper.split(\"_\")[0]  # Grab pmcid from filename\n",
    "    # Save:\n",
    "    with(open(JSON_results_dir + \"/\" + paperID + \"_\" + run_date + \".json\", \"w\")) as f:\n",
    "        cleanJSON = json.loads(response)\n",
    "        json.dump(cleanJSON, f, indent=2)\n",
    "    with(open(raw_results_dir + \"/\" + paperID + \"_\" + run_date + \".json\", \"w\")) as f:\n",
    "        f.write(completion.model_dump_json(indent=2))\n",
    "    print(\"### Finished: \", paper)\n",
    "\n",
    "if LLM_run:\n",
    "    print(\"Full run completed.\")\n",
    "else:\n",
    "    print(\"Nothing run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
