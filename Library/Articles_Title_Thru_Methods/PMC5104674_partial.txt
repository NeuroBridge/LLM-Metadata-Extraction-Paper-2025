Title.
Predicting individualized clinical measures by a generalized prediction framework and multimodal fusion of MRI data.
Abstract.
Neuroimaging techniques have greatly enhanced the understanding of neurodiversity (human brain variation across individuals) in both health and disease. The ultimate goal of using brain imaging biomarkers is to perform individualized predictions. Here we proposed a generalized framework that can predict explicit values of the targeted measures by taking advantage of joint information from multiple modalities. This framework also enables whole brain voxel-wise searching by combining multivariate techniques such as ReliefF, clustering, correlation-based feature selection and multiple regression models, which is more flexible and can achieve better prediction performance than alternative atlas-based methods. For 50 healthy controls and 47 schizophrenia patients, three kinds of features derived from resting-state fMRI (fALFF), sMRI (gray matter) and DTI (fractional anisotropy) were extracted and fed into a regression model, achieving high prediction for both cognitive scores (MCCB composite r = 0.7033, MCCB social cognition r = 0.7084) and symptomatic scores (positive and negative syndrome scale [PANSS] positive r = 0.7785, PANSS negative r = 0.7804). Moreover, the brain areas likely responsible for cognitive deficits of schizophrenia, including middle temporal gyrus, dorsolateral prefrontal cortex, striatum, cuneus and cerebellum, were located with different weights, as well as regions predicting PANSS symptoms, including thalamus, striatum and inferior parietal lobule, pinpointing the potential neuromarkers. Finally, compared to a single modality, multimodal combination achieves higher prediction accuracy and enables individualized prediction on multiple clinical measures. There is more work to be done, but the current results highlight the potential utility of multimodal brain imaging biomarkers to eventually inform clinical decision-making.
Introduction.
Predictive data mining has become a powerful tool for researchers and clinical practitioners in medicine and neuroscience. It involves building and applying theory and methods that allow for effective creation, evaluation and selection of prediction models. Neuroimaging has greatly enhanced our understanding of the human brain and its variation across individuals (neurodiversity) in health and disease. However, most criteria that used to assess severity/prognosis of brain disorders are still primarily based on clinical judgment; thus, the subjective factors of the doctors cannot be avoided. In addition, the overlapped cognitive or behavior performance of several mental disorders emphasizes the inadequacy of a diagnosis based purely on symptoms or behaviors alone and highlights the need for objective imaging neuromarkers that can assist the timely diagnosis or treatment. Therefore, using brain-imaging data to identify the neuroanatomical basis of cognitive impairment or symptom changes in brain diseases is an important research topic, since it is helpful for better understanding of the pathophysiology underlying the illness.
Predictive data mining has become popular in neuroimaging studies in a recent decade, especially for mental disorders research. Recent studies have started to use machine-learning techniques to detect neuroimaging patterns that may predict cognitive or behavioral performance. And initial brain measures have indicated compelling potential to predict health-related outcomes. However, most predictive studies to date have only related variation in baseline brain measures to variation in subsequent outcomes, which could be described more as post-diction or correlation rather than prediction. There are, however, a few examples of studies that are indeed “predicting” specific values of the target measures. For example, Wan et al. has proposed an elegant regression model called CORNLIN that employs a sparse Bayesian learning algorithm to predict multiple cognitive scores based on 98 structural MRI regions of interests (ROIs) for Alzheimer’s disease patients. The polynomial model used in CORNLIN can detect either a nonlinear or linear relationship between brain structure and cognitive decline. Stonnington et al. adopted relevance vector regression, a sparse kernel method formulated in a Bayesian framework, to predict four sets of cognitive scores using MRI voxel based morphometry measures. Wang et al. and Zhang et al. employed multi-task learning strategies for selecting biomarkers that could predict multiple clinical scores, e.g., using ℓ2–norm coupled with ℓ1-norm in regression models or multi-task feature selection coupled with a support vector machine (SVM). Integrating and testing various types of baseline data available, Ye et al. applied sparse logistic regression with stability selection to ADNI (Alzheimer’s Disease Neuroimaging Initiative) data for robust feature selection, successfully predicted the conversion from MCI to probable AD and identified a small subset of bio-signatures.
Nevertheless, many works were limited to use of a single modality, without using cross information from multiple modalities or were focused on subgroup discrimination (“classification”) instead of the particular values of the measures. In addition, quite often the input feature dimensionality is restricted, e.g. based on ROI features derived from AAL (Anatomical Automatic Labeling) templates, but without performing whole brain voxel-wise searching because of the computational load. Hence, we are motivated to propose a generalized model that is able to predict explicit values of the targeted measures by whole brain voxel-wise searching via cutting-edge machine learning algorithms and by combining joint information from multiple imaging modalities. Based on this motivation, we could use purely data-driven techniques to estimate the cognitive scores symptom changes or to classify disease subcategories using MRI measures, providing a potentially biologically valid framework for understanding mental illnesses or for even predicting the progression of the disease. This is consistent with the scope of the research domain criteria (RDoC) project proposed by NIMH, which aims to develop new ways of classifying and clarifying the underlying causes of mental disorders based on dimensions of observable behavior and neurobiological measures.
Here, we aim to achieve two main goals: 1) Design a generalized prediction framework that can be widely employed in future studies. 2) Predict target clinical measures quantitatively and identify relevant neuromarkers that could be biologically meaningful on cognitive decline/functional deficits in schizophrenia (SZ). For real human brain imaging data, we applied the framework to 47 SZ patients and 50 healthy controls (HCs) to estimate their cognitive scores, measured by the “measurement and treatment research to improve cognition in schizophrenia” (MATRICS) Consensus Cognitive Battery (MCCB) and the patients’ symptom scores, measured by the positive and negative syndrome scale (PANSS), using features extracted from three modalities: fractional amplitude of low frequency fluctuations (fALFF) from resting-state functional MRI, segmented gray matter (GM) from structural MRI and fractional anisotropy (FA) from diffusion MRI.
Note that we used the same data set as used for, however, different than the previous study that investigated the multimodal covaried networks which were not only significantly correlated with cognitive composite scores, but also showed significant differences between schizophrenia and healthy controls; this study aims to explore an approach to multimodal imaging data that enables detection of neuroimaging patterns as well as the building of a prediction model of target measures, such as cognitive scores or symptom scores. The methods used are quite distinct, the former paper adopted multi-set canonical correlation analysis, a blind source separation approach applied to group level of subjects; while the current work utilized several machine-learning techniques, including feature selection, clustering, regression and cross-validation. Results suggest the proposed prediction framework shows great promise to produce precise and individualized estimates on multiple clinical measures. Hence it’s possible to use this tool to estimate the treatment outcome for an individual patient, e.g., remitter or non-remitter, based on observable imaging measures, similar to what did in, which could enable the clinician to realistically make the personalized medical decision before treating a patient. Therefore, this project will be one of few attempts to meet clinical challenges of making early intervention possible based on fundamental neuroscience.
Materials and methods.
Theory development.
The working flowchart of proposed prediction model is shown in Fig. 1, which uses three MRI measures as an example; but this surely can be extended to other measures or modalities. The basic idea and justification of each step can be described as follows: First, considering the individuality of the predicted measures (cognition, symptoms), we remove features with very few variability across all training subjects by relative standard deviation thresholding, then based on advanced feature selection method ReliefF, we are able to select a set of most relevant features to the predicted measures. Then data-driven spatial clustering was performed to obtain fewer ROI-based features by averaging of the clusters, of which one cluster may consist several parts of the brain regions parcellated by atlas-based template, such AAL template. Note that using brain regions segmented by atlas as features is an alternative in our prediction, whereas, our proposed method is a purely data-driven feature extraction via whole brain voxel-wise searching, and achieves a higher prediction accuracy compared to AAL atlas-based methods, see results and the supplementary file (Supplementary Table S4). After this, the ROI-based features of different modalities were combined to take advantage of the multimodal complementary information, and further refined by correlation-based feature selection (CFS), producing a feature subset before regression. This step is necessary; since spatial clustering and averaging generate ROIs that compared to voxel-wise features indicate decreased relevance to target measure and may contain redundant information. Finally, by cutting-edge multiple regression models, a combination of joint brain feature subsets is formed to best predict the targeted measures. Note that all above mentioned feature selection algorithms (ReliefF, CFS) and regression models can be found in WEKA, a powerful data mining software in Java with a collection of machine learning algorithms. We will also release our prediction toolbox in future.
To avoid introducing bias into the prediction, rigorous nested cross-validation was performed. First, we left one subject for testing and used the other 96 subjects for training; then in the training layer, the 96 subjects went through a 10-fold cross-validation in the regression analysis after initial feature selection and the multimodal combination as shown in Fig. 1. This loop was repeated 97 times to test all the subjects. Each time the results produced the predicted score for the left-out (test) subject, as well as the regression equation and the identified brain regions in each modality. Then, we calculate the accuracy of the resulting prediction and identify the frequently occurring brain regions. Finally, in order to get a single regression equation for the whole MCCB prediction, we also performed a 10-fold prediction using all subjects to illustrate the identified features and regression model, as shown in Fig. 3. Next we describe the details for each step.
Feature preprocessing.
Generally speaking, specific features with only minor variation across all subjects will not be useful for prediction. By setting an appropriate threshold, we eliminate features with low standard deviation (std), which also helps reduce the dimensionality. This step is similar to variance-based thesholding that has been popularly used in DNA methylation pre-processing for dimension reduction. The std. threshold is set as   where “target” denotes the measure to be predicted. The necessity of this step is given in supplementary file, see Table S1.
Feature selection by regression ReliefF.
After obtaining representative measures from each modality, we will estimate the relevance of each voxel-wise feature to the target measure by ReliefF to derive subset of features. For continuous response values here, regression ReliefF is adapted. When processing, assume the input feature matrix X is in dimension of subjects by voxels (N × L), ReliefF randomly selects one subject Ri and searches for its k nearest neighbor subjects Ij (j = 1,2…k) based on L1 distance. For one feature (voxel/attribute) A, if it is desirable for prediction, then a bigger distance between the selected subject Ri and its nearest neighbors Ij should correspond to farther values on their predicted measures. For short, ReliefF introduces a kind of probability that the predicted values of two participants are different. This probability can be modeled with the relative distance between the predicted values of two subjects, and then are used to estimate the importance (weight) of each feature for the regression.
Assume Ndc measures two nearest subjects (e.g., Ri and Ij) have different predictions, NdA[A] determines two nearest participants have different values for the voxel/feature A, PdC &dA[A] measures two nearest participants have different predictions and different values for voxel feature A. Ndc, NdA[A] and PdC&dA[A] were updated m times for all voxels. Finally, the weight for each feature A is defined as:
While, the detailed updates for Ndc, NdA(A) and NdA(A)dC, as well as the Pseudo code of RReliefF can be found in.
Following regression ReliefF, every feature is assigned with a weight value statistically accounts for its relevance to the response values (prediction). By determining a certain output number according to the scree test (see more details in the supplementary file Supplementary Fig. S1), we can identify the most significant features in the dataset and use them as the representatives of the original voxels.
Spatial clustering.
The voxels selected via ReliefF were in general distributed sparsely across the whole brain. Here we employ a 26-connected (3 × 3 × 3-1) neighborhood strategy for image dilation, a classic way to find connected voxels in 3D image. In our case, the voxels selected out by ReliefF is 1, and the other voxels are 0. The 26-connected neighborhood voxels are neighbors to every voxel that touches one of their faces, edges, or corners. These pixels are connected along either one, two, or all three of the primary axes. These new generated voxel clusters can be projected into their corresponding areas on a brain map, enabling a useful visualization of the results. Next, these clusters are treated as the elementary features, and the mean voxel values of each cluster represent the ROI-based feature value.
Feature fusion.
Features selected from the above procedures are derived from a single modality, reflecting a view of either brain structure or function. By combining features of different modalities together in a joint analysis, potentially important variations or relationship that may only be partially detected by single modality could be revealed, and complementary information may be obtained for better prediction. At this step, in order to take advantage of joint information, all ROI-based brain features of 3 modalities were concatenated horizontally, to build a matrix in the dimension of Nsubjects by (Nfeat_fMRI + Nfeat_sMRI + Nfeat_dMRI) and then input to the feature subset selection.
Feature subset evaluation.
Although voxel-wise features selected by ReliefF are important, after spatial clustering and extract mean of the clusters, some features may have little influence on the predicted attribute. To further remove the redundancy, correlation-based feature selection (CFS) is employed. In CFS, the worth of each subset of features is evaluated by considering the individual predictive ability of each feature along with the degree of redundancy between them. Subsets of features that are highly correlated with the predicted measure while having low inter-correlation are preferred. Such a feature selection can help reduce the size of the resulting knowledge structures based on multimodal features and further yield a concise and refined data set that significantly improves the prediction performance.
Regression analysis.
Next, a final regression analysis that quantitatively captures correlations between target measures and selected brain features was implemented. If we have l, p, q number of features derived from fALFF, GM and FA, respectively, then the practical predicted values (not true target value) can be written as:
To make a performance comparison between linear and nonlinear regressions, we adopt three models: multiple linear regression, pace regression (linear) and sequential minimal optimization regression (SMOreg) (non-linear), all of which can be called and implemented through WEKA too. The latter two models are briefly introduced as follows.
PACE regression.
(Projection Adjustment by Contribution Estimation) has striking advantages over existing techniques for fitting linear models with a strong emphasis on dimensionality determination problem. Compared to classical ordinary least squares estimators that may fail to detect redundancy in a larger feature set, pace regression improves it by evaluating the effect of each variable and using a clustering analysis to improve the statistical basis for estimating their contribution to the overall regressions. Besides, pace regression adopts nonnegative-measure-based minimum distance method for solving the minority cluster problem. It can yield better prediction models with reduced model dimensionality, especially for high dimensional data. Detailed information can be found in.
Sequential minimal optimization regression.
(SMOreg) is an iterative algorithm for solving the regression problem using support vector machines (SVM). SMOreg uses the same principles as the SVM for classification, except for applying a nonlinear polynomial kernel k(xi, xj)=(xi, xj)p with p = 2 to transfer features into higher dimensional space, to make it possible to perform the linear separation. The goal of SMOreg is to estimate a function that is as “close” as possible to target values and as “flat” as possible for good generalization. More details together with a pseudo-code can be found in. As an extension of the SMO algorithm proposed by for SVM classifier design, SMOreg overcomes the issue of an important source of confusion and inefficiency caused by SMO. It globally normalizes all attributes by default, with an excellent performance on handling big samples.
Human brain data.
Participants.
Participants included a total of 47 patients with a SCID-P based DSM-IV-TR diagnosis of schizophrenia and 50 age-matched HCs (Table 1). The study was IRB approved at all participating institutions: the University of New Mexico Hospital and the Albuquerque Veterans Administration Medical Center. Participants were free of any central neurological disorder or significant head trauma and have no current diagnosis of substance abuse (>6 months before enrollment, excluding nicotine). Patients were clinically stable with no recent medication change (>4 months prior to study enrollment) across the data collection period. HCs and their first-degree relatives had no history of psychiatric disorder.
Clinical measures.
To measure the current cognitive functioning, a trained rater administered the MCCB within 1 week of imaging. A composite score was calculated via the MCCB scoring program, which is an equal weighting of seven MCCB domain scores and has been recognized as the optimal primary outcome measure. Compared with HCs, SZs achieved significantly lower scores in composite and all domains. Meanwhile, the PANSS was conducted to quantify symptom scores of patients. The negative PANSS scores and the MCCB composite were anti-correlated (R = −0.48, p = 0.0008) as expected. No significant correlation was found between MCCB composite and medication dose in SZ.
Imaging parameters.
All subjects were scanned by fMRI, sMRI and diffusion magnetic resonance imaging (dMRI), which were collected on a 3-Tesla Siemens Trio scanner with a 12-channel radio frequency coil.
fMRI.
Resting-state scans were a minimum of 5 min in duration (152 volumes). Subjects were instructed to keep their eyes open during the scan and stare passively at a presented fixation cross, as this facilitates network delineation compared to eyes-closed conditions and helps ensure that subjects are awake. Data were collected with single-shot full k-space echo-planar imaging with ramp sampling correction using the inter-commissural line (anterior commissure/posterior commissure) as a reference (TR = 2 s, TE = 29 ms, matrix size = 64 × 64, flip angle = 75°, slice thickness = 3.5 mm, slice gap = 1.05 mm, field of view (FOV) = 240 mm, matrix size = 64 × 64, voxel size = 3.75 × 3.75 × 4.55 mm3).
sMRI.
A multi-echo MPRAGE sequence was used with the following parameters: TR/TE/TI = 2530/[1.64, 3.5, 5.36, 7.22, 9.08]/900 ms, flip angle = 7°, FOV = 256 × 256 mm, slice thickness = 176 mm, matrix size = 256 × 256 × 176, voxel size = 1 × 1 × 1 mm, pixel bandwidth = 650 Hz, total scan time = 6 min.
dMRI.
Data were collected along the anterior commissure/posterior commissure line throughout the whole brain with the following parameters: FOV = 256 × 256 mm, slice thickness = 2 mm, number of excitations = 1, TE = 84 ms, TR = 9000 ms. A multiple channel radio frequency coil was used with generalized auto calibrating partially parallel acquisition (×2), 35 gradient directions, b = 800 s/mm2 and 5 measurements with b = 0.
fMRI preprocessing.
The SPM8 software package (http://www.fil.ion.ucl.ac.uk/spm/software/spm8) was employed to perform fMRI preprocessing. Slice timing was performed with the middle slice as the reference frame. Images were realigned using INRI align. The fMRI data were then despiked to mitigate the impact of outliers and spatially normalized into the standard Montreal Neurological Institute space with slightly up-sampled to 3 × 3 × 3 mm3. We further regressed out six motion parameters, white matter (WM) and CSF in de-noising, and the mean frame wise displacements showed no significant group difference (mean of root of mean square frame-to-frame head motions assuming 50 mm head radius); HC: 0.224 ± 0.12 mm, SZ: 0.227 ± 0.12 mm, p = 0.91). Finally, data were and slightly subsampled to 3 × 3 × 3 mm3 and spatially smoothed with a Gaussian kernel with full-width half maximum (FWHM) of 8 × 8 × 8 mm3. For the rest-fMRI, we extracted the voxel-wise fALFF to generate a map for each subject.
dMRI preprocessing.
Data were preprocessed by the FMRIB Software Library (www.fmrib.ox.ac.uk/fsl). All images were registered to the first b = 0 image by the FMRIB linear image registration tool. The preprocessing consisted of the following steps: (a) quality check, any gradient directions with excessive motion or vibration artifacts were identified and removed; (b) motion and eddy current correction; (c) correction of gradient directions for any image rotation done during the previous motion correction step; and (d) calculation of diffusion tensor and scalar measures such as FA, which were then resampled to 3 × 3 × 3 mm3 and smoothed by a Gaussian kernel with FWHM of 8 × 8 × 8 mm3.
sMRI preprocessing.
Data were preprocessed using the SPM8 software package to segment the brain into WM, GM, and cerebral spinal fluid with unmodulated normalized parameters via the unified segmentation method. According to, the use of unmodulated GM maps is one of the optimal settings in voxel-based morphometry analysis. Then GM images were then resampled to 3 × 3 × 3 mm3 and smoothed by a Gaussian kernel with FWHM of 8 mm. Subject outliers were detected using a spatial Pearson correlation with the template image to ensure that all subjects were properly segmented.
Normalization.
After preprocessing, the 3D brain images of each subject were reshaped into a one-dimensional vector and stacked, forming a matrix (Nsbj × Nvoxel) for each of the three modalities. These three matrices were then normalized to have the same average sum-of-squares (computed across all subjects and all voxels/locus for each modality) to ensure that all modalities had comparable ranges. Since SZ and HC were not perfectly gender matched in the current study, before prediction, the gender was regressed out to remove its potential influence on differences between groups, even though the correlation between gender and the MCCB composite score is not significant (r = 0.17, p > 0.05).
Individualized prediction.
Matrices derived from the above processing could then be treated as the original feature sets, and the corresponding cognitive/symptom scores are treated as the targeted measures; together, they serve as input to the proposed framework. Take fMRI for example, thresholding by standard deviation will prune out almost half of the total number of features, and about thousands of features will be reserved after ReliefF. During spatial clustering, with voxels organized into larger clusters, the number of features will be reduced to dozens. Finally, the features from three modalities are combined into a concatenated feature matrix that is further refined via subset feature selection, resulting in 5–15 brain regions and achieving the final prediction equation by regression analysis. In the experiment, we predicted the MCCB composite score and two domain scores (social cognition and verbal learning) with rigorous cross-validation, then evaluated PANSS positive and negative scores to verify the validity and reliability of the proposed framework.
In order to ensure the validity of the detected features, we performed an unbiased prediction flow based on nested cross-validation (10 fold + leave one out) as shown in Fig. 1, the correlations and root mean squared errors between the predicted measures and the true values are calculated in both training and testing loops, as shown in supplementary Table S3. For each modality, we could get a set of ROIs that contribute to regression and occur frequently in all loops. Note that the regression models are different at each loop; in order to get one regression model for the whole prediction, we also performed a prediction of MCCB composite using all subjects with 10 fold cross-validation. In this prediction, although in ReliefF all the training subjects were used, the selected voxel-wise features were not directly input into the pace regression, instead, these voxels were spatially clustered and refined again. Such a flow actually reduced the degree of overfitting in the training. We want to check if the frequently occurred ROI features from unbiased tests are in consistence with what we obtained from the above processing. And as we tested, the results obtained from such a working flow, as shown in Fig. 3, are quite similar to what we got from the unbiased test, see Results section.
On the other hand, the proposed method enables data-driven, voxel-wise feature searching. Indeed, using brain regions segmented by an atlas, e.g., AAL, as features can be used as an alternative. For fair comparison, we also added an alternative prediction of MCCB by combining AAL features from GM and fALFF with LASSO (least absolute shrinkage and selection operator), which is a penalized linear regression model popularly used for feature subset selection and making relevant predictions. We did not use DTI data since the AAL parcellation is based on gray matter structure, which is not suitable for FA maps representing the white matter tracts. The correlation between predicted values with the ground truth, the root mean squared prediction error (RMSE) as well as the normalized root mean squared prediction error (NRMSE) were calculated for each method using the nested cross-validation (10 fold + leave one out), as listed in Table 3. It clearly indicates that the proposed method outperformed the others in all perspectives.